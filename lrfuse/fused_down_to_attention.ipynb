{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.models.llama.modeling_llama import *\n",
    "from svd_linear import SVDLinear\n",
    "\n",
    "config = LlamaConfig()\n",
    "down_proj = nn.Linear(config.intermediate_size, config.hidden_size, bias=config.mlp_bias)\n",
    "q_proj = nn.Linear(config.hidden_size, config.hidden_size, bias=config.attention_bias)\n",
    "post_attention_layernorm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "\n",
    "input_tensor = torch.randn(1, config.intermediate_size)\n",
    "\n",
    "# Original\n",
    "down_proj_output = down_proj(input_tensor)\n",
    "\n",
    "hidden_states = post_attention_layernorm(down_proj_output)\n",
    "\n",
    "# variance = down_proj_output.pow(2).mean(-1, keepdim=True)\n",
    "# hidden_states = down_proj_output * torch.rsqrt(variance + post_attention_layernorm.variance_epsilon)\n",
    "# hidden_states = post_attention_layernorm.weight * hidden_states\n",
    "\n",
    "query_states = q_proj(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_proj_svd = SVDLinear.from_linear_rank_ratio(down_proj, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_states_svd = down_proj_svd(input_tensor)\n",
    "BLinear = down_proj_svd.BLinear\n",
    "ALinear = down_proj_svd.ALinear\n",
    "\n",
    "hidden_states_svd = BLinear(input_tensor)\n",
    "\n",
    "# hidden_states_svd = post_attention_layernorm(down_proj_output)\n",
    "weight = post_attention_layernorm.weight\n",
    "variance_epsilon = post_attention_layernorm.variance_epsilon\n",
    "\n",
    "variance = hidden_states_svd.pow(2).mean(-1, keepdim=True)\n",
    "hidden_states_svd = hidden_states_svd * torch.rsqrt(variance + variance_epsilon)\n",
    "\n",
    "hidden_states_svd = ALinear(hidden_states_svd)\n",
    "\n",
    "q_weight = torch.diag(weight) @ q_proj.weight\n",
    "\n",
    "query_states_svd = hidden_states_svd @ q_weight.T\n",
    "\n",
    "assert torch.allclose(query_states, query_states_svd, rtol=1e-2, atol=1e-2), \"Query outputs are not close enough.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1284, -0.2965, -0.5730,  ...,  0.1236,  0.4075,  0.5450]],\n",
      "       grad_fn=<MmBackward0>) tensor([[ 0.1284, -0.2965, -0.5730,  ...,  0.1236,  0.4075,  0.5450]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(query_states, query_states_svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrfuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
